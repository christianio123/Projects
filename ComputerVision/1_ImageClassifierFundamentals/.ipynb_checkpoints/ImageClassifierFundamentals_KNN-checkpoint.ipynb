{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7693c6",
   "metadata": {},
   "source": [
    "# Image Classifier Fundamentals\n",
    "\n",
    "To establish fundamentals, first a set of utilities necessary for image preprocessing and loading from the disk. Then we will use the k-Nearest Neighbor (k-NN) classifier to recognize image class labels using only the raw pixel intensities.\n",
    "\n",
    "## Dataset: \"Animals\"\n",
    "\n",
    "The \"Animals\" dataset is a simple dataset pieced together by Adrian Rosebrock to reveal the process of training an image classifier using different machine learning techniques. The dataset consists of three class labels, (1) dogs, (2) cats, and (3) pandas. Each class label has exactly 1,000 images, totaling in 3,000 images. The images within the dataset are actually subsets of both the Kaggle \"[Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats)\" challenge and the [ImageNet](https://www.image-net.org/) dataset. \n",
    "\n",
    "## Utilities\n",
    "**Image Preprocessor**\n",
    "\n",
    "Images are required to be preprocessed and scaled to have identical widths and heights suitable for machine learning algorithms. Though image preprocessing can take many forms in resizing, scaling, or respect of aspect ratio, this image preprocessor will only resize images and ignore aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ef4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import cv2\n",
    "\n",
    "class SimplePreprocessor:\n",
    "    def __init__(self, width, height, inter = cv2.INTER_AREA):\n",
    "        # store the target image width, height, and interpolation\n",
    "        # method used when resizing\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        # resize the image to a fixed size, ignoring the aspect ratio\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation = self.inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f051871",
   "metadata": {},
   "source": [
    "The imported packaged needed for our image preprocessor is cv2, otherwise known as OpenCV.\n",
    "\n",
    "Following library imports, the constructor is seen with three arguments.\n",
    "- *width*: Required, the desired width of the input image after resizing.\n",
    "- *height*: Required, the desired height of our input image after resizing. \n",
    "- *inter*: Optional, choice of interpolation algorithm when resizing.\n",
    "\n",
    "The *preprocess* function accepts a single input ad returns the desired processed image. \n",
    "\n",
    "**Image Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f114782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors = None):\n",
    "        # store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        \n",
    "        # if the preprocessors are None, initialize them as an empty list\n",
    "        if self.preprocessors is None: \n",
    "            self.preprocessors = []\n",
    "        \n",
    "    def load(self, imagePaths, verbose = -1):\n",
    "        # initialize the list of features and labels\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        # loop over the input images\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "            # load the image and extract the class label assuming\n",
    "            # that our path has the following format:\n",
    "            # /path/to/dataset/{class}/{image}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = imagePath.split(os.path.sep)[-2]\n",
    "            \n",
    "            # check to see if our preprocessors are not None\n",
    "            if self.preprocessors is not None:\n",
    "                # loop over preprocessors and apply each to the image\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "                    \n",
    "            # treat our processed image as a 'feature vector'\n",
    "            # by updating the data list followed by the labels\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "                print(\"[INFO] processed {}/{}\".format(i + 1, len(imagePaths)))\n",
    "                \n",
    "        # return a tuple of the data and labels\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e5c80",
   "metadata": {},
   "source": [
    "The following library packages are imported:\n",
    "- *numpy* - for numerical processing\n",
    "- *cv2* - for OpenCV bindings\n",
    "- *os* - to extract names of subdirectories in image paths\n",
    "\n",
    "The constructor has one optional argument, *preprocessors*, in which a list of desired preprocessors can be inputed to process images accordingly. The input type being a list is important to being able to perform sequential modifications, such as resizing an image first and then scaling the resized image. \n",
    "\n",
    "The *load* function requires one argument, *imagePaths*, referring to the location of the dataset within the disk. Verbose refers to viewing the active updates taking place while the function is performing its objective. The *data* and *labels* variables begin an empty list in which to store the data we will iterate through given that *preprocessors* is not equal to *None*. \n",
    "\n",
    "## k-Nearest Neighbors (k-NN)\n",
    "\n",
    "The k-NN algorithm is simple enough in which no 'learning' is actually taking place. Rather, k-NN is dependent on the distance feature vectors (RGB pixel intensities). That is, the algorithm classifies data points by finding the most common class among *k* closest 'points'. Whichever label has the most data points closest to the image of interest is considered the most likely label. The underlying assumption is images with the same class label will share similar characteristics between different images (i.e., data points), and this will be seen when expressed as a feature vector. \n",
    "\n",
    "We will use four steps to train a k-NN algorithm to classify the *animals* dataset based on the raw pixel intensities of images. \n",
    "\n",
    "1. Gather Dataset - Each image of the 'animals' dataset will be preprocessed using our SimplePreprocessor.\n",
    "2. Split Dataset - The dataset will be split into a training and testing set. \n",
    "3. Train Classifier - The k-NN classifier will be trained on the training dataset. \n",
    "4. Evaluate - The k-NNs performance will be evaluated on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a324c11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 1000/3000\n",
      "[INFO] processed 2000/3000\n",
      "[INFO] processed 3000/3000\n",
      "[INFO] features matrix: 8.8MB\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "\n",
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "imagePaths = list(paths.list_images('datasets//animals'))\n",
    "\n",
    "# initialize the image preprocessor, load the data from disk and reshape the data matrix\n",
    "sp = SimplePreprocessor(32,32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data,labels) = sdl.load(imagePaths, verbose = 1000)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# show information on memory consumption of the images\n",
    "print(\"[INFO] features matrix: {:.1f}MB\".format(data.nbytes / (1024 * 1024.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21dc094",
   "metadata": {},
   "source": [
    "Imported Library Packages\n",
    "- KNeighborsClassifier: implements the k-NN algorithm\n",
    "- LabelEncoder: converts labels represented as strings into unique integers per class\n",
    "- train_test_split: function to help create a training and test set\n",
    "- classification_report: utility function to help evaluate performance\n",
    "\n",
    "________\n",
    "\n",
    "*imagePaths* is used to store the file paths to all the images in the 'animals' dataset. Afterwards, *SimplePreprocessor* is initialized to resize images to 32x32 pixels. Next *SimpleDatasetLoader* is with our *SimplePreprocessor* as it's preprocessor in order to return both the image and it's correponding label.\n",
    "\n",
    "Because our data's shape is originally a numpy array of (3,000, 32, 32, 3), we will 'flatten' the three-dimensional array into a single list that a k-NN algorithm can understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f7762de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels as integers \n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of the data for training and 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08293a11",
   "metadata": {},
   "source": [
    "*labels* is originally represent as just a list of strings, therefore to create 'categories' or classes, we use the LabelEncoder function to convert these strings into integers. Afterwards the data is partitioned into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67eb66bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating k-NN classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.77      0.54       262\n",
      "           1       0.35      0.31      0.33       249\n",
      "           2       0.88      0.15      0.26       239\n",
      "\n",
      "    accuracy                           0.42       750\n",
      "   macro avg       0.55      0.41      0.38       750\n",
      "weighted avg       0.54      0.42      0.38       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifier on the raw pixel intensities \n",
    "print(\"[INFO] evaluating k-NN classifier...\")\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 2, n_jobs = -1)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "print(classification_report(testY, model.predict(testX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e0813f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating k-NN classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.61      0.50       262\n",
      "           1       0.39      0.47      0.42       249\n",
      "           2       0.91      0.27      0.41       239\n",
      "\n",
      "    accuracy                           0.45       750\n",
      "   macro avg       0.57      0.45      0.44       750\n",
      "weighted avg       0.57      0.45      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifier on the raw pixel intensities \n",
    "print(\"[INFO] evaluating k-NN classifier...\")\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5, n_jobs = -1)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "print(classification_report(testY, model.predict(testX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7250a",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "Two k-NN classifiers were conducted. The first k-NN classifier measuring the closest 2 images based on raw pixel intensity and the second k-NN classifier based on the closest 5 images. We see that our k-NN classifier performs better when taking into account the closest 5 images based on raw pixel intensity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
