{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7693c6",
   "metadata": {},
   "source": [
    "# Image Classifier Fundamentals\n",
    "\n",
    "To establish fundamentals, first a set of utilities necessary for image preprocessing and loading from the disk. Then we will use the k-Nearest Neighbor (k-NN) classifier to recognize image class labels using only the raw pixel intensities.\n",
    "\n",
    "## Dataset: \"Animals\"\n",
    "\n",
    "The \"Animals\" dataset is a simple dataset pieced together by Adrian Rosebrock to reveal the process of training an image classifier using different machine learning techniques. The dataset consists of three class labels, (1) dogs, (2) cats, and (3) pandas. Each class label has exactly 1,000 images, totaling in 3,000 images. The images within the dataset are actually subsets of both the Kaggle \"[Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats)\" challenge and the [ImageNet](https://www.image-net.org/) dataset. \n",
    "\n",
    "## Utilities\n",
    "**Image Preprocessor**\n",
    "\n",
    "Images are required to be preprocessed and scaled to have identical widths and heights suitable for machine learning algorithms. Though image preprocessing can take many forms in resizing, scaling, or respect of aspect ratio, this image preprocessor will only resize images and ignore aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ef4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import cv2\n",
    "\n",
    "class SimplePreprocessor:\n",
    "    def __init__(self, width, height, inter = cv2.INTER_AREA):\n",
    "        # store the target image width, height, and interpolation\n",
    "        # method used when resizing\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.inter = inter\n",
    "        \n",
    "    def preprocess(self, image):\n",
    "        # resize the image to a fixed size, ignoring the aspect ratio\n",
    "        return cv2.resize(image, (self.width, self.height), interpolation = self.inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f051871",
   "metadata": {},
   "source": [
    "The imported packaged needed for our image preprocessor is cv2, otherwise known as OpenCV.\n",
    "\n",
    "Following library imports, the constructor is seen with three arguments.\n",
    "- *width*: Required, the desired width of the input image after resizing.\n",
    "- *height*: Required, the desired height of our input image after resizing. \n",
    "- *inter*: Optional, choice of interpolation algorithm when resizing.\n",
    "\n",
    "The *preprocess* function accepts a single input ad returns the desired processed image. \n",
    "\n",
    "**Image Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f114782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors = None):\n",
    "        # store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        \n",
    "        # if the preprocessors are None, initialize them as an empty list\n",
    "        if self.preprocessors is None: \n",
    "            self.preprocessors = []\n",
    "        \n",
    "    def load(self, imagePaths, verbose = -1):\n",
    "        # initialize the list of features and labels\n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        # loop over the input images\n",
    "        for (i, imagePath) in enumerate(imagePaths):\n",
    "            # load the image and extract the class label assuming\n",
    "            # that our path has the following format:\n",
    "            # /path/to/dataset/{class}/{image}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = imagePath.split(os.path.sep)[-2]\n",
    "            \n",
    "            # check to see if our preprocessors are not None\n",
    "            if self.preprocessors is not None:\n",
    "                # loop over preprocessors and apply each to the image\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "                    \n",
    "            # treat our processed image as a 'feature vector'\n",
    "            # by updating the data list followed by the labels\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "                print(\"[INFO] processed {}/{}\".format(i + 1, len(imagePaths)))\n",
    "                \n",
    "        # return a tuple of the data and labels\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e5c80",
   "metadata": {},
   "source": [
    "The following library packages are imported:\n",
    "- *numpy* - for numerical processing\n",
    "- *cv2* - for OpenCV bindings\n",
    "- *os* - to extract names of subdirectories in image paths\n",
    "\n",
    "The constructor has one optional argument, *preprocessors*, in which a list of desired preprocessors can be inputed to process images accordingly. The input type being a list is important to being able to perform sequential modifications, such as resizing an image first and then scaling the resized image. \n",
    "\n",
    "The *load* function requires one argument, *imagePaths*, referring to the location of the dataset within the disk. Verbose refers to viewing the active updates taking place while the function is performing its objective. The *data* and *labels* variables begin an empty list in which to store the data we will iterate through given that *preprocessors* is not equal to *None*. \n",
    "\n",
    "## k-Nearest Neighbors (k-NN)\n",
    "\n",
    "The k-NN algorithm is simple enough in which no 'learning' is actually taking place. Rather, k-NN is dependent on the distance feature vectors (RGB pixel intensities). That is, the algorithm classifies data points by finding the most common class among *k* closest 'points'. Whichever label has the most data points closest to the image of interest is considered the most likely label. The underlying assumption is images with the same class label will share similar characteristics between different images (i.e., data points), and this will be seen when expressed as a feature vector. \n",
    "\n",
    "We will use four steps to train a k-NN algorithm to classify the *animals* dataset based on the raw pixel intensities of images. \n",
    "\n",
    "1. Gather Dataset - Each image of the 'animals' dataset will be preprocessed using our SimplePreprocessor.\n",
    "2. Split Dataset - The dataset will be split into a training and testing set. \n",
    "3. Train Classifier - The k-NN classifier will be trained on the training dataset. \n",
    "4. Evaluate - The k-NNs performance will be evaluated on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a324c11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -d DATASET [-k NEIGHBORS] [-j JOBS]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -d/--dataset\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from imutils import paths\n",
    "import argparse\n",
    "\n",
    "# construct the argument parse and parse the arguments \n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required = True, help = \"path to input dataset\")\n",
    "ap.add_argument(\"-k\", \"--neighbors\", type = int, default = 1, help = \"# of nearest neighbors for classification\")\n",
    "ap.add_argument(\"-j\", \"--jobs\", type = int, default = -1, help = \"# of jobs for k-NN distance (-1 uses all available cores)\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# grab the list of images we will be describing \n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images[\"dataset\"])\n",
    "\n",
    "# initialize the image preprocessor, load the dataset from disk, \n",
    "# and reshape the data matrix\n",
    "sp = SimplePreprocessor(32,32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, labels) = sdl.load(imagePaths, verbose = 500)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# show some information on memory consumption of the images\n",
    "print(\"[INFO] features matrix: {:1f}MB\".format(data.nbytes / (1024 * 1024.0)))\n",
    "\n",
    "# encode the labels as integers \n",
    "le = LabelEncoder()\n",
    "labels= le.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of the data\n",
    "# for training and the remaining 25% for testing\n",
    "print(\"[INFO] evaluating a k-NN classifier...\")\n",
    "model = KNeighborsClassifier(n_neighbors = args['neighbors'],\n",
    "                             n_jobs = args[\"jobs\"])\n",
    "model.fit(trainX,trainY)\n",
    "print(classificationreport(testY, model.predict(testX),\n",
    "                          target_names = le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9da85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6896a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cb858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da6f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
